# Aprendizagem por instâncias (KNN)

livros sobre o tópico

````
Capítulo 6 do livro Data Classification de Charu C. Aggarwal (Instance Based Learning: A Survey): apresenta a teoria e exemplos de aplicações

Artigo Instance-based learning algorithms de David W. Aha, Dennis Kibler e Marc K. Albert: mostra vários algoritmos de aprendizagem baseada em instâncias
````

link:
Doc do KNN do SciKit-Learning
https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html

## KNN - K-Nearest Neighbour (K vizinhos mais próximos)

Como fuciona: você calcula a distãncia de um ponto a todos os outros da base de dados. Apartir dessa distância classifico a row. 

!!! OBS: SEM ESCOLANAMENTO, ELE NÂO FUNCIONA DIREITO (STANDARSCALER)

A ideia é: classificar a amostra de acordo com os outros dados  mais próximos da amostra. Como utiliza um cláculo de distância, a base deve ser de inteiros. Tmabém importa fazer um escalonamento nos dados

Técnicas de Escalonamento (para um atributos nÂo ter mais valor que outro)

Durante a etapa de normalização, os valores são alterados para uma escala entre 0 e 1. Por outro lado, na padronização os dados são alterados levando em consideração a média e desvio padrão

Normalizaçâo
x = x -min(x) / (max(x) - min(x)

Padronização
x = x - média(x) / (desvio_padrão(x))

O valor "K" é a quantidade de vizinhos mais próximo que vou olahr para classificar uma amostra.

Críterio para os K vizinhos
1. Classifica a amostra pela maior contagem de classes dos K vizinhos
2. Se houver empate (todas as clases tem mesma qtd) entâo, o critério de desempate será o vizinho mais próxmi

Exemplo
+ K = 1
	- Vai buscar o mais próximo
+ K = 2
	- Vai buscar os dois mais próximos. Se tiverem classes diferente escolherra

Se vocẽ escolher um K muito grande, provavlemnte pode piorar o treinamento, por pegar dados demais.

KNN GERAL

• 
• A maioria dos métodos de aprendizagem constroem um modelo após
o treinamento (os dados são descartados após a criação do modelo) mas em Métodos baseados em instâncias simplesmente armazenam os
exemplos de treinamento. OU seja, tem que guardar os dados de treinamento.
• Entâo nâo chega a ser um treinamento, e sim um cálculo entre a nova amsotra e a base de dados. 
• ELE NÂO CONSTROI MODELO, SÓ FAZ CÁLCULO DE DISTÂNCIA.
• A generalização/previsão é feita somente quando uma nova instância
precisa ser classificada (lazy:preguiçoso, pois nâo gera modelo)

CÁLCULO DA DISTÂNCIA

+ Em geral, utiliza a distância Euclidiana

Como é visto o KNN
+ Simples e Poderoso
+ Indicado quando o relacionamento entre as características é complexo
+ Valor de K pequeno: Dados com ruidos e outliers podem prejudicar
+ Valor de K grande: tendência a classificar a classe com mais elementos (overfitting). 
+ Em geral, o valor default de K é entre \[3, 5\]
+ É lento para fazer previsões (faz muitos cálculos, 1 para cada dados da base passada para ele)
+ Distãncias
	- Coeficiente de PEarson
	- Índice de Tanimoto
	- City Block






