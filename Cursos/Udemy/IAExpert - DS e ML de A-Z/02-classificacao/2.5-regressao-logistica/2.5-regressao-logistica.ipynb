{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T21:08:39.266763Z",
     "start_time": "2019-12-31T21:08:29.172403Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "file_path = \"../../files/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Logística para `risco_credit` com somente duas classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T21:32:58.175923Z",
     "start_time": "2019-12-31T21:32:58.158905Z"
    }
   },
   "outputs": [],
   "source": [
    "base = pd.read_csv(file_path + 'risco_credito2.csv')\n",
    "previsores = base.iloc[:,0:4].values\n",
    "classe = base.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T21:33:12.760669Z",
     "start_time": "2019-12-31T21:33:12.747674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['ruim', 'alta', 'nenhuma', '0_15'],\n",
       "       ['desconhecida', 'alta', 'nenhuma', '15_35'],\n",
       "       ['desconhecida', 'baixa', 'nenhuma', 'acima_35'],\n",
       "       ['desconhecida', 'baixa', 'nenhuma', 'acima_35'],\n",
       "       ['desconhecida', 'baixa', 'adequada', 'acima_35'],\n",
       "       ['ruim', 'baixa', 'nenhuma', '0_15'],\n",
       "       ['boa', 'baixa', 'nenhuma', 'acima_35'],\n",
       "       ['boa', 'alta', 'adequada', 'acima_35'],\n",
       "       ['boa', 'alta', 'nenhuma', '0_15'],\n",
       "       ['boa ', 'alta', 'nenhuma', 'acima_35'],\n",
       "       ['ruim', 'alta', 'nenhuma', '15_35']], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Antes do LabelEncoder\n",
    "previsores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T21:33:15.785001Z",
     "start_time": "2019-12-31T21:33:15.769502Z"
    }
   },
   "outputs": [],
   "source": [
    "# PreProcessamento\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "previsores[:,0] = labelencoder.fit_transform(previsores[:,0])\n",
    "previsores[:,1] = labelencoder.fit_transform(previsores[:,1])\n",
    "previsores[:,2] = labelencoder.fit_transform(previsores[:,2])\n",
    "previsores[:,3] = labelencoder.fit_transform(previsores[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T21:33:16.160963Z",
     "start_time": "2019-12-31T21:33:16.150256Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 1, 0],\n",
       "       [2, 0, 1, 1],\n",
       "       [2, 1, 1, 2],\n",
       "       [2, 1, 1, 2],\n",
       "       [2, 1, 0, 2],\n",
       "       [3, 1, 1, 0],\n",
       "       [0, 1, 1, 2],\n",
       "       [0, 0, 0, 2],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 1, 2],\n",
       "       [3, 0, 1, 1]], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LabelEncoder: converter dados categóricos em numéros\n",
    "previsores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A equação da regressão logística é mais ou meno\n",
    "\n",
    "````\n",
    "y = cte + a*f1 + b*f2 + c*f3 + d*f4 + e*f5\n",
    "\n",
    "Onde:\n",
    "+ f1, f2 , ..., f5 sãoas features\n",
    "+ a,b, .. , e são os pesos\n",
    "+ cte é melhor constante encontrada\n",
    "````\n",
    "\n",
    "OBSERVE QUE É MUITO SEMELHANTE À REDES NEURAIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classificador  LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T21:33:17.111426Z",
     "start_time": "2019-12-31T21:33:17.096874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.52358972]\n",
      "[[-0.65034407  0.25428474 -0.45375558  1.17384764]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classificador = LogisticRegression()\n",
    "classificador.fit(previsores, classe)\n",
    "print(classificador.intercept_) # Constante da Equação: cte\n",
    "print(classificador.coef_) # Pesos para cada feature: a,b..,e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T21:33:17.565149Z",
     "start_time": "2019-12-31T21:33:17.554898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['baixo' 'alto']\n",
      "[[0.20256331 0.79743669]\n",
      " [0.92234346 0.07765654]]\n"
     ]
    }
   ],
   "source": [
    "## CLASSIFICANDO os seguintes dados\n",
    "# história boa, dívida alta, garantias nenhuma, renda > 35\n",
    "# história ruim, dívida alta, garantias adequada, renda < 15\n",
    "\n",
    "# PREDIZER CLASSE\n",
    "resultado = classificador.predict([[0,0,1,2], [3, 0, 0, 0]])\n",
    "print(resultado)\n",
    "\n",
    "# PROBABILIDADE\n",
    "resultado2 = classificador.predict_proba([[0,0,1,2], [3, 0, 0, 0]])\n",
    "print(resultado2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Logistica `credit_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T21:34:06.274021Z",
     "start_time": "2019-12-31T21:34:05.800155Z"
    }
   },
   "outputs": [],
   "source": [
    "base = pd.read_csv(file_path + 'credit_data.csv')\n",
    "base.loc[base.age < 0, 'age'] = 40.92\n",
    "               \n",
    "previsores = base.iloc[:, 1:4].values\n",
    "classe = base.iloc[:, 4].values\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "imputer = imputer.fit(previsores[:, 1:4])\n",
    "previsores[:, 1:4] = imputer.transform(previsores[:, 1:4])\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "previsores = scaler.fit_transform(previsores)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(\n",
    "    previsores, classe, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T21:34:09.348338Z",
     "start_time": "2019-12-31T21:34:09.127632Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classificador = LogisticRegression(random_state = 1, solver='lbfgs')\n",
    "classificador.fit(previsores_treinamento, classe_treinamento)\n",
    "previsoes = classificador.predict(previsores_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T21:39:42.565426Z",
     "start_time": "2019-12-31T21:39:42.537214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.946\n",
      "Matrix de Confusao\n",
      " [[423  13]\n",
      " [ 14  50]] \n",
      "\n",
      "Matrix de Confusao Porcentagem\n",
      " [[0.846 0.026]\n",
      " [0.028 0.1  ]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       436\n",
      "           1       0.79      0.78      0.79        64\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.88      0.88      0.88       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "precisao = accuracy_score(classe_teste, previsoes)\n",
    "matriz = confusion_matrix(classe_teste, previsoes)\n",
    "print(\"Accuracy\", precisao)\n",
    "print(\"Matrix de Confusao\\n\",matriz, \"\\n\")\n",
    "print(\"Matrix de Confusao Porcentagem\\n\",matriz/matriz.sum(), \"\\n\")\n",
    "print(classification_report(classe_teste,previsoes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T21:11:48.860368Z",
     "start_time": "2019-12-31T21:11:48.855638Z"
    }
   },
   "source": [
    "## Regressão Logística `census`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T21:41:54.393790Z",
     "start_time": "2019-12-31T21:41:53.615263Z"
    }
   },
   "outputs": [],
   "source": [
    "base = pd.read_csv(file_path + 'census.csv')\n",
    "\n",
    "previsores = base.iloc[:, 0:14].values\n",
    "classe = base.iloc[:, 14].values\n",
    "                \n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "column_tranformer = ColumnTransformer(\n",
    "    [('one_hot_encoder', OneHotEncoder(), [1, 3, 5, 6, 7, 8, 9, 13])],\n",
    "    remainder='passthrough')\n",
    "previsores = column_tranformer.fit_transform(previsores).toarray()\n",
    "\n",
    "labelencorder_classe = LabelEncoder()\n",
    "classe = labelencorder_classe.fit_transform(classe)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "previsores = scaler.fit_transform(previsores)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(\n",
    "    previsores, classe, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T21:41:57.338370Z",
     "start_time": "2019-12-31T21:41:56.526138Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classificador = LogisticRegression(solver='lbfgs')\n",
    "classificador.fit(previsores_treinamento, classe_treinamento)\n",
    "previsoes = classificador.predict(previsores_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T21:42:15.941298Z",
     "start_time": "2019-12-31T21:42:15.888925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.849539406345957 \n",
      "\n",
      "Matrix de Confusao\n",
      " [[3423  270]\n",
      " [ 465  727]] \n",
      "\n",
      "Matrix de Confusao Porcentagem\n",
      " [[0.70071648 0.05527124]\n",
      " [0.09518936 0.14882293]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90      3693\n",
      "           1       0.73      0.61      0.66      1192\n",
      "\n",
      "    accuracy                           0.85      4885\n",
      "   macro avg       0.80      0.77      0.78      4885\n",
      "weighted avg       0.84      0.85      0.84      4885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "precisao = accuracy_score(classe_teste, previsoes)\n",
    "matriz = confusion_matrix(classe_teste, previsoes)\n",
    "print(\"Accuracy\", precisao, \"\\n\")\n",
    "print(\"Matrix de Confusao\\n\",matriz, \"\\n\")\n",
    "print(\"Matrix de Confusao Porcentagem\\n\",matriz/matriz.sum(), \"\\n\")\n",
    "print(classification_report(classe_teste,previsoes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTIONS ENGLISH ML-AZ\n",
    "\n",
    "#### Logistic Regression Intuition\n",
    "\n",
    "Is Logistic Regression a linear or non linear model?\n",
    "\n",
    "It is a linear model. You will visualize this at the end of the section when seeing that the classifier’s separator\n",
    "is a straight line.\n",
    "\n",
    "What are the Logistic Regression assumptions?\n",
    "\n",
    "First, binary logistic regression requires the dependent variable to be binary and ordinal logistic regression\n",
    "requires the dependent variable to be ordinal.\n",
    "\n",
    "Second, logistic regression requires the observations to be independent of each other. In other words, the\n",
    "observations should not come from repeated measurements or matched data.\n",
    "\n",
    "Third, logistic regression requires there to be little or no multicollinearity among the independent variables.\n",
    "This means that the independent variables should not be too highly correlated with each other.\n",
    "Fourth, logistic regression assumes linearity of independent variables and log odds. although this analy-\n",
    "sis does not require the dependent and independent variables to be related linearly, it requires that the\n",
    "independent variables are linearly related to the log odds.\n",
    "\n",
    "Can Logistic Regression be used for many independent variables as well?\n",
    "\n",
    "Yes, Logistic Regression can be used for as many independent variables as you want. However be aware that\n",
    "you won’t be able to visualize the results in more than 3 dimensions.\n",
    "\n",
    "#### Logistic Regression in Python\n",
    "\n",
    "What does the fit method do here?\n",
    "The fit method will basically train the Logistic Regression model on the training data. Therefore it will\n",
    "compute and get the weights (coefficients) of the Logistic Regression model (see the Intuition Lecture) for\n",
    "that particular set of training data composed of X_train and y_train. Then right after it collects the\n",
    "weights/coefficients, you have a Logistic Regression model fully trained on your training data, and ready to\n",
    "predict new outcomes thanks to the predict method.\n",
    "\n",
    "We predicted the outcomes of a set of observations (the test set). How do we do the same for\n",
    "a single observation, to predict a single outcome?\n",
    "\n",
    "Let’s say this observation has the following features: Age = 30, Estimated Salary = 50000.\n",
    "Then the code to get the predicted outcome would be the following (notice how we must not forget to scale\n",
    "that single observation first):\n",
    "\n",
    "`y_pred = classifier.predict(sc_X.transform(np.array([[20, 50000]])))`\n",
    "\n",
    "Is the Confusion Matrix the optimal way to evaluate the performance of the model?\n",
    "\n",
    "No, it just gives you an idea of how well your model can perform. If you get a good confusion matrix with\n",
    "few prediction errors on the test set, then there is a chance your model has a good predictive power. However\n",
    "the most relevant way to evaluate your model is through K-Fold Cross Validation, which you will see in Part\n",
    "10. It consists of evaluating your model on several test sets (called the validation sets), so that we can make\n",
    "sure we don’t get lucky on one single test set. Today most Data Scientists or AI Developers evaluate their\n",
    "model through K-Fold Cross Validation. However the technique is a different subject so I preferred to leave\n",
    "it for Part 10 after we cover all the different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
