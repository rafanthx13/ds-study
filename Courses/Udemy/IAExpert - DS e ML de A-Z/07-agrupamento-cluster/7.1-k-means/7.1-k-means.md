# K-means

## Exemplos de Utilidade

+ Fazer segmnetação de clientes
+ Fazer agrupamento de notícias
+ Identificar perfis similares de usuários (netflix)

## Aprendizagem nâo-supervisionada

**LEMBRE-SE: É UMA APRENDIZAGEM NÃO-SUPERVISIONADA, NÂO HÁ CLASSES**

Ele identifica padrões; Onde começa e termina cada grupo

Grupo/CLuster: Elementos de um mesmo cluster/grupo devem ser similares e diferentes dos que estão fora do grupo

## Algorimo de Loyd (k-means)

1. Inicializar os centroides aleatoriamente (centros de um cluster)
2. Para cada ponto na base de dados, calcular a distância para cada
centroide e associar ao que estiver mais perto
3. Calcular a média de todos os pontos ligados a cada centroide e
definir um novo centroide (repetir as etapas 2 e 3)

Distancia Euclidiana

DistEuclidiana(x,y) = sqrt(sum(x_i - y_i)^2))

## k-means++

+ Reduz a probabilidade de inicializações ruins
+ Seleciona os centroides iniciais que estão longes uns dos outros
+ O primeiro centroide é selecionado randomicamente, porém, os
outros são selecionados baseado na distância para o primeiro ponto


## Definiçâo do número de clusters

+ Ter um conhecimento prévio de quantos grupos são necessários
+ Se nâo tiver conhecimento prévio
	clusters = sqrt(N/2) onde N é o núermo de elementos
+ Elbow method: Tentar vários valores de k
+ Não existe garantia para encontrar o melhor conjunto de clusters. Isso depende do contexto

## Elbow method

Testa com k=1,2,3,4,5,6 e aquele que tiver uama melhor métrica, ele escolhe como o ideal.

**Métrica** Within-cluster sum of squares
+ Que é a disntacia de cada um dos pontos para cada um dos centroides, assim, quanto maior, pior.
+ Se também tiver um valor muito pequeno, ela vai considerar cada elemento isoladamente como um cluster
+ Quanto maior o valor, peior é esse k

+ O ideal entâo é fazer um gráfico e identificar o ponto em que há um grande ganho sem que seja muita classes. E também, depende do contexto




